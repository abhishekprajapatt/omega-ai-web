export interface VoiceConfig {  language: string;  rate: number;   pitch: number;   volume: number;   voiceIndex?: number;  continuous?: boolean;  interimResults?: boolean;  maxAlternatives?: number;}export interface TranscriptResult {  text: string;  isFinal: boolean;  confidence: number;  alternatives?: string[];}export interface SpeechOptions {  text: string;  language?: string;  rate?: number;  pitch?: number;  volume?: number;  voiceIndex?: number;  onStart?: () => void;  onEnd?: () => void;  onError?: (error: string) => void;}export class VoiceListener {  private recognition: SpeechRecognition | null = null;  private isListening: boolean = false;  private config: VoiceConfig;  private transcript: string = '';  private interimTranscript: string = '';  constructor(config: Partial<VoiceConfig> = {}) {    this.config = {      language: config.language || 'en-US',      rate: config.rate || 1.0,      pitch: config.pitch || 1.0,      volume: config.volume || 1.0,      continuous: config.continuous ?? true,      interimResults: config.interimResults ?? true,      maxAlternatives: config.maxAlternatives || 1,    };    if (typeof window === 'undefined') {      this.recognition = null;      return;    }    const SpeechRecognition =      window.SpeechRecognition ||      (window as any).webkitSpeechRecognition ||      null;    if (!SpeechRecognition) {      console.warn('Speech Recognition API not supported in this browser');      this.recognition = null;    } else {      this.recognition = new SpeechRecognition();      this.setupRecognition();    }  }  private setupRecognition(): void {    if (!this.recognition) return;    this.recognition.continuous = this.config.continuous ?? true;    this.recognition.interimResults = this.config.interimResults ?? true;    this.recognition.maxAlternatives = this.config.maxAlternatives || 1;    this.recognition.lang = this.config.language;  }  public startListening(    onResult: (result: TranscriptResult) => void,    onError?: (error: string) => void,  ): void {    if (!this.recognition) {      onError?.('Speech Recognition not supported');      return;    }    this.isListening = true;    this.transcript = '';    this.interimTranscript = '';    this.recognition.onstart = () => {      console.log('Listening started...');    };    this.recognition.onresult = (event: SpeechRecognitionEvent) => {      this.interimTranscript = '';      for (let i = event.resultIndex; i < event.results.length; i++) {        const transcript = event.results[i][0].transcript;        if (event.results[i].isFinal) {          this.transcript += transcript + ' ';        } else {          this.interimTranscript += transcript;        }      }      const isFinal = event.results[event.results.length - 1]?.isFinal ?? false;      const confidence =        event.results[event.results.length - 1]?.[0]?.confidence ?? 0;      onResult({        text: (this.transcript + this.interimTranscript).trim(),        isFinal,        confidence,      });    };    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {      const errorMessage = `Speech Recognition Error: ${event.error}`;      console.error(errorMessage);      onError?.(errorMessage);    };    this.recognition.onend = () => {      console.log('Listening stopped');      this.isListening = false;    };    try {      this.recognition.start();    } catch (error) {      console.warn('Recognition already running');    }  }  public stopListening(): void {    if (this.recognition && this.isListening) {      this.recognition.stop();      this.isListening = false;    }  }  public abort(): void {    if (this.recognition) {      this.recognition.abort();      this.isListening = false;    }  }  public getIsListening(): boolean {    return this.isListening;  }  public getTranscript(): string {    return this.transcript;  }  public resetTranscript(): void {    this.transcript = '';    this.interimTranscript = '';  }  public setLanguage(language: string): void {    this.config.language = language;    if (this.recognition) {      this.recognition.lang = language;    }  }  public static isSupported(): boolean {    if (typeof window === 'undefined') return false;    return !!(      window.SpeechRecognition || (window as any).webkitSpeechRecognition    );  }}export class VoiceSynthesizer {  private synthesis: SpeechSynthesis | null = null;  private config: VoiceConfig;  private utterance: SpeechSynthesisUtterance | null = null;  private isSpeaking: boolean = false;  private availableVoices: SpeechSynthesisVoice[] = [];  constructor(config: Partial<VoiceConfig> = {}) {    if (typeof window === 'undefined') {      this.synthesis = null;      this.config = {        language: 'en-US',        rate: 1.0,        pitch: 1.0,        volume: 0.85,      };      return;    }    this.synthesis = window.speechSynthesis || null;    this.config = {      language: config.language || 'en-US',      rate: Math.max(0.5, Math.min(2.0, config.rate || 1.0)),      pitch: Math.max(0, Math.min(2.0, config.pitch || 1.0)),      volume: Math.max(0, Math.min(1.0, config.volume || 1.0)),      voiceIndex: config.voiceIndex || 0,    };    this.loadVoices();  }  private loadVoices(): void {    if (!this.synthesis) return;    this.availableVoices = this.synthesis.getVoices();    if (this.availableVoices.length === 0) {      this.synthesis.onvoiceschanged = () => {        this.availableVoices = this.synthesis!.getVoices();      };    }  }  public async speak(options: SpeechOptions): Promise<void> {    if (!this.synthesis) {      options.onError?.('Text-to-Speech not supported');      return;    }    this.synthesis.cancel();    this.utterance = new SpeechSynthesisUtterance(options.text);    this.utterance.lang = options.language || this.config.language;    this.utterance.rate = options.rate || this.config.rate;    this.utterance.pitch = options.pitch || this.config.pitch;    this.utterance.volume = options.volume || this.config.volume;    const voiceIndex = options.voiceIndex || this.config.voiceIndex || 0;    if (      this.availableVoices.length > 0 &&      voiceIndex < this.availableVoices.length    ) {      this.utterance.voice = this.availableVoices[voiceIndex];    }    this.utterance.onstart = () => {      this.isSpeaking = true;      options.onStart?.();    };    this.utterance.onend = () => {      this.isSpeaking = false;      options.onEnd?.();    };    this.utterance.onerror = (event: SpeechSynthesisErrorEvent) => {      this.isSpeaking = false;      options.onError?.(`Speech Synthesis Error: ${event.error}`);    };    this.synthesis.speak(this.utterance);  }  public pause(): void {    if (this.synthesis && this.synthesis.speaking && !this.synthesis.paused) {      this.synthesis.pause();    }  }  public resume(): void {    if (this.synthesis && this.synthesis.paused) {      this.synthesis.resume();    }  }  public stop(): void {    if (this.synthesis) {      this.synthesis.cancel();      this.isSpeaking = false;    }  }  public getIsSpeaking(): boolean {    return this.isSpeaking || (this.synthesis?.speaking ?? false);  }  public getVoices(): SpeechSynthesisVoice[] {    return this.availableVoices;  }  public getVoicesForLanguage(language: string): SpeechSynthesisVoice[] {    return this.availableVoices.filter((voice) =>      voice.lang.startsWith(language),    );  }  public setLanguage(language: string): void {    this.config.language = language;  }  public setVoiceByIndex(index: number): void {    this.config.voiceIndex = index;  }  public setVoiceByName(voiceName: string): void {    const voiceIndex = this.availableVoices.findIndex(      (v) => v.name === voiceName,    );    if (voiceIndex >= 0) {      this.config.voiceIndex = voiceIndex;    }  }  public static isSupported(): boolean {    return typeof window !== 'undefined' && !!window.speechSynthesis;  }}export class AudioProcessor {  private audioContext: AudioContext | null = null;  private analyser: AnalyserNode | null = null;  private dataArray: Uint8Array | null = null;  private animationFrameId: number | null = null;  constructor() {    if (typeof window !== 'undefined') {      const AudioContextClass =        window.AudioContext || (window as any).webkitAudioContext;      this.audioContext = new AudioContextClass();    }  }  public setupVisualization(    mediaStreamSource: MediaStreamAudioSourceNode,  ): void {    if (!this.audioContext) return;    this.analyser = this.audioContext.createAnalyser();    this.analyser.fftSize = 2048;    const bufferLength = this.analyser.frequencyBinCount;    this.dataArray = new Uint8Array(bufferLength);    mediaStreamSource.connect(this.analyser);  }  public getFrequencyData(): Uint8Array | null {    if (this.analyser && this.dataArray) {      this.analyser.getByteFrequencyData(this.dataArray as any);      return this.dataArray;    }    return null;  }  public getWaveformData(): Uint8Array | null {    if (this.analyser && this.dataArray) {      this.analyser.getByteTimeDomainData(this.dataArray as any);      return this.dataArray;    }    return null;  }  public getAverageFrequency(): number {    const data = this.getFrequencyData();    if (!data) return 0;    const sum = data.reduce((a, b) => a + b, 0);    return sum / data.length;  }  public isSoundDetected(threshold: number = 30): boolean {    return this.getAverageFrequency() > threshold;  }  public close(): void {    if (this.animationFrameId) {      cancelAnimationFrame(this.animationFrameId);    }  }  public static isSupported(): boolean {    if (typeof window === 'undefined') return false;    return !!(window.AudioContext || (window as any).webkitAudioContext);  }}export function detectLanguage(text: string): string {  const patterns: Record<string, RegExp> = {    'es-ES': /[\u00E0\u00E1\u00E9\u00ED\u00F3\u00FA\u00FC]/g,     'fr-FR': /[\u00E0\u00E9\u00E8\u00EA\u00E7\u00F9]/g,     'de-DE': /[\u00E4\u00F6\u00FC\u00DF]/g,     'ja-JP': /[\u3040-\u309F\u30A0-\u30FF]/g,     'zh-CN': /[\u4E00-\u9FFF]/g,     'en-US': /[a-zA-Z]/g,   };  for (const [lang, pattern] of Object.entries(patterns)) {    if (pattern.test(text)) {      return lang;    }  }  return 'en-US'; }export function calculateConfidence(  confidence: number,  alternatives?: string[],): number {  let score = confidence;  if (alternatives && alternatives.length > 0) {    score *= 1 - alternatives.length * 0.1;  }  return Math.max(0, Math.min(1, score));}export interface EmotionModulation {  rate: number;  pitch: number;  volume: number;}export function getEmotionModulation(  emotion:    | 'happy'    | 'sad'    | 'angry'    | 'calm'    | 'excited'    | 'neutral' = 'neutral',): EmotionModulation {  const modulations: Record<string, EmotionModulation> = {    happy: { rate: 1.2, pitch: 1.3, volume: 0.9 },    sad: { rate: 0.8, pitch: 0.8, volume: 0.7 },    angry: { rate: 1.1, pitch: 1.2, volume: 1.0 },    calm: { rate: 0.9, pitch: 0.9, volume: 0.8 },    excited: { rate: 1.3, pitch: 1.4, volume: 1.0 },    neutral: { rate: 1.0, pitch: 1.0, volume: 0.85 },  };  return modulations[emotion] || modulations.neutral;}export async function convertSpeechToTextAPI(  audioData: Blob | ArrayBuffer,  language: string = 'en',  provider: 'openai' | 'google' | 'deepgram' = 'openai',): Promise<{  transcript: string;  confidence: number;  provider: string;  error?: string;}> {  try {    let base64Audio: string;    if (audioData instanceof Blob) {      const arrayBuffer = await audioData.arrayBuffer();      base64Audio = Buffer.from(arrayBuffer).toString('base64');    } else if (audioData instanceof ArrayBuffer) {      base64Audio = Buffer.from(audioData).toString('base64');    } else {      throw new Error('Invalid audio data format');    }    const response = await fetch('/api/stt', {      method: 'POST',      headers: {        'Content-Type': 'application/json',      },      body: JSON.stringify({        audio: base64Audio,        language,        provider,      }),    });    if (!response.ok) {      const errorData = await response.json().catch(() => ({}));      throw new Error(errorData.error || `STT API error: ${response.status}`);    }    const data = await response.json();    return {      transcript: data.transcript || '',      confidence: data.confidence || 0,      provider: data.provider || provider,    };  } catch (error) {    const errorMessage =      error instanceof Error ? error.message : 'Unknown STT error';    console.error('STT API Error:', errorMessage);    return {      transcript: '',      confidence: 0,      provider,      error: errorMessage,    };  }}export async function convertTextToSpeechAPI(  text: string,  language: string = 'en-US',  voiceId?: string,  model: 'elevenlabs' | 'openai' | 'google' = 'openai',): Promise<{  audio: Blob | null;  error?: string;}> {  try {    if (!text || text.trim().length === 0) {      throw new Error('Text is required for TTS');    }    if (text.length > 5000) {      throw new Error('Text too long (maximum 5000 characters)');    }    const response = await fetch('/api/tts', {      method: 'POST',      headers: {        'Content-Type': 'application/json',      },      body: JSON.stringify({        text,        language,        voiceId,        model,        format: 'mp3',      }),    });    if (!response.ok) {      const errorData = await response.json().catch(() => ({}));      throw new Error(errorData.error || `TTS API error: ${response.status}`);    }    const audioBlob = await response.blob();    return {      audio: audioBlob,    };  } catch (error) {    const errorMessage =      error instanceof Error ? error.message : 'Unknown TTS error';    console.error('TTS API Error:', errorMessage);    return {      audio: null,      error: errorMessage,    };  }}export function audioBlobToBase64(blob: Blob): Promise<string> {  return new Promise((resolve, reject) => {    const reader = new FileReader();    reader.onloadend = () => {      const base64 = reader.result?.toString().split(',')[1];      if (base64) {        resolve(base64);      } else {        reject(new Error('Failed to convert blob to base64'));      }    };    reader.onerror = reject;    reader.readAsDataURL(blob);  });}export function base64ToAudioBlob(  base64: string,  type: string = 'audio/mp3',): Blob {  const binaryString = atob(base64);  const bytes = new Uint8Array(binaryString.length);  for (let i = 0; i < binaryString.length; i++) {    bytes[i] = binaryString.charCodeAt(i);  }  return new Blob([bytes], { type });}export async function recordAudioFromMicrophone(  durationMs: number = 5000,): Promise<{  audio: Blob | null;  error?: string;}> {  try {    if (typeof window === 'undefined') {      throw new Error('Recording not available on server');    }    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });    const mediaRecorder = new MediaRecorder(stream);    const audioChunks: Blob[] = [];    mediaRecorder.ondataavailable = (event) => {      audioChunks.push(event.data);    };    mediaRecorder.start();    await new Promise((resolve) => setTimeout(resolve, durationMs));    mediaRecorder.stop();    await new Promise((resolve) => {      mediaRecorder.onstop = resolve;    });    stream.getTracks().forEach((track) => track.stop());    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });    return {      audio: audioBlob,    };  } catch (error) {    const errorMessage =      error instanceof Error ? error.message : 'Unknown recording error';    console.error('Audio Recording Error:', errorMessage);    return {      audio: null,      error: errorMessage,    };  }}