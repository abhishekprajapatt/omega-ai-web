export interface VoiceConfig {  language: string;  rate: number;  pitch: number;  volume: number;  voiceIndex?: number;  continuous?: boolean;  interimResults?: boolean;  maxAlternatives?: number;}export interface TranscriptResult {  text: string;  isFinal: boolean;  confidence: number;  alternatives?: string[];}export interface VoiceListenerOptions {  language?: string;  continuous?: boolean;  interimResults?: boolean;  maxAlternatives?: number;}export interface SpeechOptions {  text: string;  language?: string;  rate?: number;  pitch?: number;  volume?: number;  voiceIndex?: number;  onStart?: () => void;  onEnd?: () => void;  onError?: (error: string) => void;}export interface SpeechSynthesisVoiceOptions {  voiceIndex?: number;  language?: string;}export interface AudioData {  frequency: Uint8Array | null;  waveform: Uint8Array | null;  average: number;}export interface VisualizationConfig {  width?: number;  height?: number;  barCount?: number;  smoothing?: number;}export interface UseVoiceConversationOptions {  onTranscript?: (transcript: string, isFinal: boolean) => void;  onError?: (error: string) => void;  onListeningStart?: () => void;  onListeningEnd?: () => void;  onSpeakingStart?: () => void;  onSpeakingEnd?: () => void;  onProcessingStart?: () => void;  language?: string;  voiceRate?: number;  voicePitch?: number;  voiceVolume?: number;  emotion?: 'happy' | 'sad' | 'angry' | 'calm' | 'excited' | 'neutral';  autoPlay?: boolean;}export interface VoiceConversationState {  isListening: boolean;  isSpeaking: boolean;  isProcessing: boolean;  transcript: string;  error: string | null;}export interface VoiceConversationReturn extends VoiceConversationState {  startListening: () => Promise<void>;  stopListening: () => void;  playResponse: (    text: string,    customOptions?: Partial<SpeechOptions>,  ) => Promise<void>;  stopSpeaking: () => void;  clearTranscript: () => void;  getTranscript: () => string;  getAvailableVoices: () => SpeechSynthesisVoice[];  getAudioData: () => AudioData | null;  setLanguage: (language: string) => void;  setVoiceByName: (voiceName: string) => void;  isSupported: {    listener: boolean;    synthesizer: boolean;    audioProcessor: boolean;  };}export type Emotion =  | 'happy'  | 'sad'  | 'angry'  | 'calm'  | 'excited'  | 'neutral';export interface EmotionModulation {  rate: number;  pitch: number;  volume: number;}export type EmotionMap = Record<Emotion, EmotionModulation>;export type LanguageCode =  | 'en-US'  | 'en-GB'  | 'es-ES'  | 'fr-FR'  | 'de-DE'  | 'ja-JP'  | 'zh-CN'  | 'pt-BR'  | 'ru-RU'  | 'ko-KR'  | 'it-IT'  | 'nl-NL'  | 'tr-TR'  | 'pl-PL'  | 'ar-SA'  | 'hi-IN'  | 'th-TH'  | 'vi-VN'  | string; export interface LanguageInfo {  code: LanguageCode;  name: string;  nativeName?: string;  flag?: string;}export interface TTSRequest {  text: string;  language?: LanguageCode;  voiceId?: string;  model?: 'elevenlabs' | 'openai' | 'google';  format?: 'mp3' | 'wav' | 'ogg';}export interface TTSResponse {  success: boolean;  audioUrl?: string;  duration?: number;  model?: string;  error?: string;}export interface STTRequest {  audio: string;   language?: LanguageCode;  provider?: 'openai' | 'google' | 'deepgram';}export interface STTResponse {  success: boolean;  transcript?: string;  confidence?: number;  provider?: string;  alternatives?: string[];  error?: string;}export interface ChatAIRequest {  chatId: string;  prompt: string;  images?: string[];  model?: 'deepseek' | 'openai' | 'grok' | 'gemini' | 'claude';}export interface ChatAIResponse {  success: boolean;  data?: {    response: string;    model: string;    tokens?: number;  };  error?: string;}export interface VoiceService {  name: string;  provider: string;  supported: boolean;  features: {    languages: LanguageCode[];    emotions: Emotion[];    streaming?: boolean;    caching?: boolean;  };}export interface VoiceProfile {  id: string;  name: string;  language: LanguageCode;  emotion: Emotion;  rate: number;  pitch: number;  volume: number;  provider: 'browser' | 'openai' | 'elevenlabs' | 'google';}export interface VoiceConversationComponentProps {  isOpen: boolean;  onClose: () => void;  onTranscriptComplete?: (transcript: string) => void;  language?: LanguageCode;  emotion?: Emotion;}export interface EnhancedVoiceInputModalProps {  isOpen: boolean;  onClose: () => void;  onTranscriptComplete?: (transcript: string) => void;  language?: LanguageCode;  emotion?: Emotion;}export type VoiceErrorType =  | 'NO_MICROPHONE'  | 'PERMISSION_DENIED'  | 'NOT_SUPPORTED'  | 'NETWORK_ERROR'  | 'API_ERROR'  | 'TTS_ERROR'  | 'STT_ERROR'  | 'TRANSCRIPTION_ERROR'  | 'UNKNOWN_ERROR';export interface VoiceError extends Error {  type: VoiceErrorType;  code?: string;  statusCode?: number;  details?: Record<string, any>;}export interface VoiceEvent {  type:    | 'listening_start'    | 'listening_end'    | 'speaking_start'    | 'speaking_end'    | 'processing_start'    | 'processing_end'    | 'transcript_interim'    | 'transcript_final'    | 'error';  timestamp: number;  data?: any;}export interface VoiceEventListener {  (event: VoiceEvent): void;}export interface VoiceStatistics {  totalConversations: number;  totalListeningTime: number;   totalSpeakingTime: number;   averageTranscriptionAccuracy: number;   averageResponseTime: number;   errorRate: number;   languagesUsed: LanguageCode[];  emotionsUsed: Emotion[];}export interface VoiceSystemConfig {  defaultLanguage: LanguageCode;  defaultEmotion: Emotion;  defaultVoiceRate: number;  defaultVoicePitch: number;  defaultVoiceVolume: number;  autoPlayResponse: boolean;  enableVisualization: boolean;  enableStatistics: boolean;  cacheResponses: boolean;  cacheDuration: number;   maxTranscriptLength: number;  silenceDuration: number;   inactivityTimeout: number; }export interface SpeechRecognitionEvent extends Event {  results: SpeechRecognitionResultList;  resultIndex: number;  isFinal?: boolean;}export interface SpeechRecognitionErrorEvent extends Event {  error: string;}export interface SpeechSynthesisUtterance {  text: string;  lang: string;  rate: number;  pitch: number;  volume: number;  voice: SpeechSynthesisVoice | null;  onstart: ((event: SpeechSynthesisEvent) => void) | null;  onend: ((event: SpeechSynthesisEvent) => void) | null;  onerror: ((event: SpeechSynthesisErrorEvent) => void) | null;  onpause: ((event: SpeechSynthesisEvent) => void) | null;  onresume: ((event: SpeechSynthesisEvent) => void) | null;}export interface SpeechSynthesis {  speaking: boolean;  paused: boolean;  pending: boolean;  onvoiceschanged: ((event: Event) => void) | null;  speak(utterance: SpeechSynthesisUtterance): void;  cancel(): void;  pause(): void;  resume(): void;  getVoices(): SpeechSynthesisVoice[];}export interface SpeechSynthesisVoice {  voiceURI: string;  name: string;  lang: string;  localService: boolean;  default: boolean;}export interface LanguageDetectionResult {  language: LanguageCode;  confidence: number;  alternatives: Array<{    language: LanguageCode;    confidence: number;  }>;}export interface ConfidenceCalculationOptions {  alternatives?: string[];  weight?: number;}export type UseVoiceConversationReturn = VoiceConversationReturn;export type AnyLanguage = LanguageCode;export type AnyEmotion = Emotion;export type AnyVoiceEvent = VoiceEvent;